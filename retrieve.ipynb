{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd06b6801f3ceb00a16ca1ea0c3b5d9c621aee9ecfe65a44177e8e5bff249ec0097",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Retrieving top 'n' resumes for a given job description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading vectorizer and models\n",
    "vectorizer = joblib.load('vectorizer.joblib')   \n",
    "linear_SVC = joblib.load('model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Job description is for Data Science category\n"
     ]
    }
   ],
   "source": [
    "# Job Description\n",
    "job_desc = []\n",
    "with open('JobDescriptions\\job-description-DataScientist.txt',\"r\", encoding='UTF8', errors='ignore') as jdf:\n",
    "    job_desc.append(jdf.read())\n",
    "job_desc = pd.DataFrame(job_desc, columns=['Content'])\n",
    "\n",
    "preprocessed_job_desc = preprocess(job_desc.loc[[0], 'Content'])    # Preprocessing job description\n",
    "job_desc = vectorizer.transform(preprocessed_job_desc)              # Vectorizing\n",
    "\n",
    "job_category = linear_SVC.predict(job_desc)[0]                      # Predicting the category\n",
    "print(f'Job description is for {job_category} category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Resume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Science</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Science</td>\n      <td>Education Details \\nMay 2013 to May 2017 B.E  ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Science</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Science</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Science</td>\n      <td>Education Details \\n MCA   YMCAUST,  Faridabad...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>Testing</td>\n      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>Testing</td>\n      <td>â Willingness to accept the challenges. â ...</td>\n    </tr>\n    <tr>\n      <th>959</th>\n      <td>Testing</td>\n      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>Testing</td>\n      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>Testing</td>\n      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n    </tr>\n  </tbody>\n</table>\n<p>962 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "resume_dataset = pd.read_csv('Labelled_Resume_Dataset.csv')\n",
    "resume_dataset"
   ]
  },
  {
   "source": [
    "We can use classify.ipynb to label an unlabelled dataset and then perform the following tasks\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    index                                             Resume\n",
       "0       0  Skills * Programming Languages: Python (pandas...\n",
       "1       1  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
       "2       2  Areas of Interest Deep Learning, Control Syste...\n",
       "3       3  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4       4  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
       "5       5  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...\n",
       "6       6  Skills â¢ Python â¢ Tableau â¢ Data Visuali...\n",
       "7       7  Education Details \\n B.Tech   Rayat and Bahra ...\n",
       "8       8  Personal Skills â¢ Ability to quickly grasp t...\n",
       "9       9  Expertise â Data and Quantitative Analysis â...\n",
       "10     10  Skills * Programming Languages: Python (pandas...\n",
       "11     11  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
       "12     12  Areas of Interest Deep Learning, Control Syste...\n",
       "13     13  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "14     14  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
       "15     15  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...\n",
       "16     16  Skills â¢ Python â¢ Tableau â¢ Data Visuali...\n",
       "17     17  Education Details \\n B.Tech   Rayat and Bahra ...\n",
       "18     18  Personal Skills â¢ Ability to quickly grasp t...\n",
       "19     19  Expertise â Data and Quantitative Analysis â...\n",
       "20     20  Skills * Programming Languages: Python (pandas...\n",
       "21     21  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
       "22     22  Areas of Interest Deep Learning, Control Syste...\n",
       "23     23  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "24     24  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
       "25     25  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...\n",
       "26     26  Skills â¢ Python â¢ Tableau â¢ Data Visuali...\n",
       "27     27  Education Details \\n B.Tech   Rayat and Bahra ...\n",
       "28     28  Personal Skills â¢ Ability to quickly grasp t...\n",
       "29     29  Expertise â Data and Quantitative Analysis â...\n",
       "30     30  Skills * Programming Languages: Python (pandas...\n",
       "31     31  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
       "32     32  Areas of Interest Deep Learning, Control Syste...\n",
       "33     33  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "34     34  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
       "35     35  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...\n",
       "36     36  Skills â¢ Python â¢ Tableau â¢ Data Visuali...\n",
       "37     37  Education Details \\n B.Tech   Rayat and Bahra ...\n",
       "38     38  Personal Skills â¢ Ability to quickly grasp t...\n",
       "39     39  Expertise â Data and Quantitative Analysis â..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Resume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Education Details \\nMay 2013 to May 2017 B.E  ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Education Details \\n MCA   YMCAUST,  Faridabad...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Skills â¢ Python â¢ Tableau â¢ Data Visuali...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Education Details \\n B.Tech   Rayat and Bahra ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Personal Skills â¢ Ability to quickly grasp t...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Expertise â Data and Quantitative Analysis â...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>Education Details \\nMay 2013 to May 2017 B.E  ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>Education Details \\n MCA   YMCAUST,  Faridabad...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>Skills â¢ Python â¢ Tableau â¢ Data Visuali...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>Education Details \\n B.Tech   Rayat and Bahra ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>Personal Skills â¢ Ability to quickly grasp t...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>Expertise â Data and Quantitative Analysis â...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>Education Details \\nMay 2013 to May 2017 B.E  ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>Education Details \\n MCA   YMCAUST,  Faridabad...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>Skills â¢ Python â¢ Tableau â¢ Data Visuali...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>Education Details \\n B.Tech   Rayat and Bahra ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>Personal Skills â¢ Ability to quickly grasp t...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>Expertise â Data and Quantitative Analysis â...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>Skills * Programming Languages: Python (pandas...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>Education Details \\nMay 2013 to May 2017 B.E  ...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>Areas of Interest Deep Learning, Control Syste...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>Education Details \\n MCA   YMCAUST,  Faridabad...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>Skills â¢ Python â¢ Tableau â¢ Data Visuali...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>Education Details \\n B.Tech   Rayat and Bahra ...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>Personal Skills â¢ Ability to quickly grasp t...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>Expertise â Data and Quantitative Analysis â...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Retrieving all rows with predicted category\n",
    "predicted_category_resume = pd.DataFrame(resume_dataset[resume_dataset['Category'] == job_category]['Resume'], columns=['Resume'])  \n",
    "predicted_category_resume.reset_index(inplace=True)\n",
    "predicted_category_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_resumes = preprocess(predicted_category_resume['Resume'])  # Preprocessing retrieved resumes\n",
    "preprocessed_resumes.append(preprocessed_job_desc[0])                   # appending preprocessed job description\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))     # Creating a clean vectorizer\n",
    "vectorized_resumes = vectorizer.fit_transform(preprocessed_resumes)     # Vectorizing resumes and jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(vectorized_resumes[-1], vectorized_resumes).flatten()    # Getting cosine similarity\n",
    "cosine_sim = np.delete(cosine_sim, -1)  # Deleting cosine similarity of job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rience - 6 months\nRETAIL MARKETING- Exprience - 6 months\nSCM- Exprience - 6 months\nSQL- Exprience - Less than 1 year months\nDeep Learning- Exprience - Less than 1 year months\nMachine learning- Exprience - Less than 1 year months\nPython- Exprience - Less than 1 year months\nR- Exprience - Less than 1 year monthsCompany Details \ncompany - Deloitte USI\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\nKey Responsibilities:\nâ¢ Extract data from client systems across geographies.\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\nTechnical Environment: R, Tableau.\n\nIndustry: Cross Industry\nService Area: Cross Industry - Products\nProject Name: Handwriting recognition\nConsultant: 3 months.\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\nRole: I was developing sentence correction functionality.\nKey Responsibilities:\nâ¢ Gather data large enough to capture all English words\nâ¢ Train LSTM models on words.\nTechnical Environment: Python.\n\nIndustry: Finance\nService Area: Financial Services - BI development Project Name: SWIFT\nConsultant: 8 months.\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\nfinancial reports to respective departments. Reporting also included forecasting expenses.\nRole: I was leading the offshore team.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop ETL for data flow\nâ¢ Validate various reports.\nTechnical Environment: SAP HANA, Tableau, SAP AO.\n\nIndustry: Healthcare Analytics\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\nConsultant: 2 months.\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\nmodels for insights.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop and deploy analytical models.\nâ¢ Validate various reports.\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\n\nIndustry: FMCG\nService Area: Trade & Promotion\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\nThe project involved setting up of CRM and CBP modules.\nRole: I was involved in key data decomposition activities and setting up the base for future year\nforecast. Over the course of the project I developed various models and carried out key\nperformance improvements.\nKey Responsibilities:\nâ¢ Design & Develop HANA models for decomposition.\nâ¢ Develop data flow for forecast.\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\nâ¢ Validate various reports in BOBJ.\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\n\nInternal Initiative Industry: FMCG\nCustomer Segmentation and RFM analysis Consultant; 3 months.\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\n\nIndustry: Telecom Invoice state detection Consultant; 1 months.\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\nreduction by 60%.\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\n\nAccenture Experience\nIndustry: Analytics - Cross Industry\nIn Process Analytics for SAP Senior Developer; 19 months.\nAccenture Solutions Pvt. Ltd., India\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\nKey Responsibilities:\nâ¢ Involved in information gather phase.\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\nCalculation View.\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\nâ¢ Created procedures in HANA Database.\nâ¢ Took ownership and developed Dashboard functionality.\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\nTechnical Environment: R, SAP HANA, T-SQL.\nIndustry: Cross Industry\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\nAccenture Solutions Pvt. Ltd., India\nRole: I have taken care of all development activities for the ATAS tool and have also completed\nvarious deployments of the product.\nApart from these activities I was also actively involved in maintenance of the database servers\n(Production & Quality)\nKey Responsibilities:\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\ninteracting with business and further transform all requirements to generate attribute\nmapping documents and reviewing mapping specification documentation\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\nâ¢ Responsible for Designing, developing and Normalization of database tables\nâ¢ Experience in performance tuning using SQL profiler.\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL.\n\n\t\t\t\t\t\t\t++++++++\n\nSkills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\nData Science Consultant \n\nConsultant - Deloitte USI\nSkill Details \nLINEAR PROGRAMMING- Exprience - 6 months\nRETAIL- Exprience - 6 months\nRETAIL MARKETING- Exprience - 6 months\nSCM- Exprience - 6 months\nSQL- Exprience - Less than 1 year months\nDeep Learning- Exprience - Less than 1 year months\nMachine learning- Exprience - Less than 1 year months\nPython- Exprience - Less than 1 year months\nR- Exprience - Less than 1 year monthsCompany Details \ncompany - Deloitte USI\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\nKey Responsibilities:\nâ¢ Extract data from client systems across geographies.\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\nTechnical Environment: R, Tableau.\n\nIndustry: Cross Industry\nService Area: Cross Industry - Products\nProject Name: Handwriting recognition\nConsultant: 3 months.\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\nRole: I was developing sentence correction functionality.\nKey Responsibilities:\nâ¢ Gather data large enough to capture all English words\nâ¢ Train LSTM models on words.\nTechnical Environment: Python.\n\nIndustry: Finance\nService Area: Financial Services - BI development Project Name: SWIFT\nConsultant: 8 months.\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\nfinancial reports to respective departments. Reporting also included forecasting expenses.\nRole: I was leading the offshore team.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop ETL for data flow\nâ¢ Validate various reports.\nTechnical Environment: SAP HANA, Tableau, SAP AO.\n\nIndustry: Healthcare Analytics\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\nConsultant: 2 months.\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\nmodels for insights.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop and deploy analytical models.\nâ¢ Validate various reports.\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\n\nIndustry: FMCG\nService Area: Trade & Promotion\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\nThe project involved setting up of CRM and CBP modules.\nRole: I was involved in key data decomposition activities and setting up the base for future year\nforecast. Over the course of the project I developed various models and carried out key\nperformance improvements.\nKey Responsibilities:\nâ¢ Design & Develop HANA models for decomposition.\nâ¢ Develop data flow for forecast.\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\nâ¢ Validate various reports in BOBJ.\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\n\nInternal Initiative Industry: FMCG\nCustomer Segmentation and RFM analysis Consultant; 3 months.\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\n\nIndustry: Telecom Invoice state detection Consultant; 1 months.\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\nreduction by 60%.\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\n\nAccenture Experience\nIndustry: Analytics - Cross Industry\nIn Process Analytics for SAP Senior Developer; 19 months.\nAccenture Solutions Pvt. Ltd., India\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\nKey Responsibilities:\nâ¢ Involved in information gather phase.\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\nCalculation View.\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\nâ¢ Created procedures in HANA Database.\nâ¢ Took ownership and developed Dashboard functionality.\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\nTechnical Environment: R, SAP HANA, T-SQL.\nIndustry: Cross Industry\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\nAccenture Solutions Pvt. Ltd., India\nRole: I have taken care of all development activities for the ATAS tool and have also completed\nvarious deployments of the product.\nApart from these activities I was also actively involved in maintenance of the database servers\n(Production & Quality)\nKey Responsibilities:\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\ninteracting with business and further transform all requirements to generate attribute\nmapping documents and reviewing mapping specification documentation\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\nâ¢ Responsible for Designing, developing and Normalization of database tables\nâ¢ Experience in performance tuning using SQL profiler.\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL.\n\n\t\t\t\t\t\t\t++++++++\n\nSkills â¢ R â¢ Python â¢ SAP HANA â¢ Tableau â¢ SAP HANA SQL â¢ SAP HANA PAL â¢ MS SQL â¢ SAP Lumira â¢ C# â¢ Linear Programming â¢ Data Modelling â¢ Advance Analytics â¢ SCM Analytics â¢ Retail Analytics â¢Social Media Analytics â¢ NLP Education Details \nJanuary 2017 to January 2018 PGDM Business Analytics  Great Lakes Institute of Management & Illinois Institute of Technology\nJanuary 2013 Bachelor of Engineering Electronics and Communication Bengaluru, Karnataka New Horizon College of Engineering, Bangalore Visvesvaraya Technological University\nData Science Consultant \n\nConsultant - Deloitte USI\nSkill Details \nLINEAR PROGRAMMING- Exprience - 6 months\nRETAIL- Exprience - 6 months\nRETAIL MARKETING- Exprience - 6 months\nSCM- Exprience - 6 months\nSQL- Exprience - Less than 1 year months\nDeep Learning- Exprience - Less than 1 year months\nMachine learning- Exprience - Less than 1 year months\nPython- Exprience - Less than 1 year months\nR- Exprience - Less than 1 year monthsCompany Details \ncompany - Deloitte USI\ndescription - The project involved analysing historic deals and coming with insights to optimize future deals.\nRole: Was given raw data, carried out end to end analysis and presented insights to client.\nKey Responsibilities:\nâ¢ Extract data from client systems across geographies.\nâ¢ Understand and build reports in tableau. Infer meaningful insights to optimize prices and find out process blockades.\nTechnical Environment: R, Tableau.\n\nIndustry: Cross Industry\nService Area: Cross Industry - Products\nProject Name: Handwriting recognition\nConsultant: 3 months.\nThe project involved taking handwritten images and converting them to digital text images by object detection and sentence creation.\nRole: I was developing sentence correction functionality.\nKey Responsibilities:\nâ¢ Gather data large enough to capture all English words\nâ¢ Train LSTM models on words.\nTechnical Environment: Python.\n\nIndustry: Finance\nService Area: Financial Services - BI development Project Name: SWIFT\nConsultant: 8 months.\nThe project was to develop an analytics infrastructure on top of SAP S/4, it would user to view\nfinancial reports to respective departments. Reporting also included forecasting expenses.\nRole: I was leading the offshore team.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop ETL for data flow\nâ¢ Validate various reports.\nTechnical Environment: SAP HANA, Tableau, SAP AO.\n\nIndustry: Healthcare Analytics\nService Area: Life Sciences - Product development Project Name: Clinical Healthcare System\nConsultant: 2 months.\nThe project was to develop an analytics infrastructure on top of Argus, it would allow users to query faster and provide advance analytics capabilities.\nRole: I was involved from design to deploy phase, performed a lot of data restructuring and built\nmodels for insights.\nKey Responsibilities:\nâ¢ Design & Develop data models for reporting.\nâ¢ Develop and deploy analytical models.\nâ¢ Validate various reports.\nTechnical Environment: Data Modelling, SAP HANA, Tableau, NLP.\n\nIndustry: FMCG\nService Area: Trade & Promotion\nProject Name: Consumption Based Planning for Flowers Foods Consultant; 8 months.\nThe project involved setting up of CRM and CBP modules.\nRole: I was involved in key data decomposition activities and setting up the base for future year\nforecast. Over the course of the project I developed various models and carried out key\nperformance improvements.\nKey Responsibilities:\nâ¢ Design & Develop HANA models for decomposition.\nâ¢ Develop data flow for forecast.\nâ¢ Developed various views for reporting of Customer/Sales/Funds.\nâ¢ Validate various reports in BOBJ.\nTechnical Environment: Data Modelling, SAP HANA, BOBJ, Time Series Forecasting.\n\nInternal Initiative Industry: FMCG\nCustomer Segmentation and RFM analysis Consultant; 3 months.\nThe initiative involved setting up of HANA-Python interface and advance analytics on Python. Over the course I had successfully segmented data into five core segments using K-means and carried out RFM analysis in Python. Also developed algorithm to categorize any new customer under the defined buckets.\nTechnical Environment: Anaconda3, Python3.6, HANA SPS12\n\nIndustry: Telecom Invoice state detection Consultant; 1 months.\nThe initiative was to reduce the manual effort in verifying closed and open invoices manually, it\ninvolved development to a decision tree to classify open/closed invoices. This enabled effort\nreduction by 60%.\nTechnical Environment: R, SAP PAL, SAP HANA SPS12\n\nAccenture Experience\nIndustry: Analytics - Cross Industry\nIn Process Analytics for SAP Senior Developer; 19 months.\nAccenture Solutions Pvt. Ltd., India\nThe project involved development of SAP analytics tool - In Process Analytics (IPA) . My role was to develop database objects and data models to provide operational insights to clients.\nRole: I have developed various Finance related KPIs and spearheaded various deployments.\nIntroduced SAP Predictive analytics to reduce development time and reuse functionalities for KPIs and prepared production planning reports.\nKey Responsibilities:\nâ¢ Involved in information gather phase.\nâ¢ Designed and implemented SAP HANA data modelling using Attribute View, Analytic View, and\nCalculation View.\nâ¢ Developed various KPI's individually using complex SQL scripts in Calculation views.\nâ¢ Created procedures in HANA Database.\nâ¢ Took ownership and developed Dashboard functionality.\nâ¢ Involved in building data processing algorithms to be executed in R server for cluster analysis.\nTechnical Environment: R, SAP HANA, T-SQL.\nIndustry: Cross Industry\nAccenture Testing Accelerator for SAP Database Developer; 21 months.\nAccenture Solutions Pvt. Ltd., India\nRole: I have taken care of all development activities for the ATAS tool and have also completed\nvarious deployments of the product.\nApart from these activities I was also actively involved in maintenance of the database servers\n(Production & Quality)\nKey Responsibilities:\nâ¢ Analyzing business requirements, understanding the scope, getting requirements clarified\ninteracting with business and further transform all requirements to generate attribute\nmapping documents and reviewing mapping specification documentation\nâ¢ Create / Update database objects like tables, views, stored procedures, function, and packages\nâ¢ Monitored SQL Server Error Logs and Application Logs through SQL Server Agent\nâ¢ Prepared Data Flow Diagrams, Entity Relationship Diagrams using UML\nâ¢ Responsible for Designing, developing and Normalization of database tables\nâ¢ Experience in performance tuning using SQL profiler.\nâ¢ Involved in QA, UAT, knowledge transfer and support activities\nTechnical Environment: SQL Server 2008/2014, Visual Studio 2010, Windows Server, Performance\nMonitor, SQL Server Profiler, C#, PL-SQL, T-SQL.\n\n\t\t\t\t\t\t\t++++++++\n\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "num_of_resumes = 10     # Top n relevant resumes\n",
    "\n",
    "# Iterating over dataframe and appending a tuple with cosine similarities, index and resume data\n",
    "for idx, row in predicted_category_resume.iterrows():\n",
    "    data.append((cosine_sim[idx]*100, idx, row['Resume']))\n",
    "\n",
    "data.sort(reverse=True)     # Sorting according to cosine similarity\n",
    "for idx, record in enumerate(data[:(num_of_resumes+1)]):    # Getting n relevant resumes\n",
    "    print(record[2], end = '\\n\\n\\t\\t\\t\\t\\t\\t\\t++++++++\\n\\n')\n",
    "    with open(f'Resumes\\{str(idx)}_resume.txt', 'w', encoding='UTF8') as f:\n",
    "        f.write(record[2])"
   ]
  }
 ]
}